{"step": 1, "data": {"train/loss": 1.371673345565796, "train/grad_norm": 22.66242027282715, "train/lr": 5.0000000000000004e-08, "train/mfu": 0.019935151053160315, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 2, "data": {"train/loss": 1.4300709962844849, "train/grad_norm": 22.221534729003906, "train/lr": 1.0000000000000001e-07, "train/mfu": 0.02986124022567911, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 3, "data": {"train/loss": 1.344076156616211, "train/grad_norm": 21.389543533325195, "train/lr": 1.5000000000000002e-07, "train/mfu": 0.030569782374574368, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 4, "data": {"train/loss": 1.385377049446106, "train/grad_norm": 21.57584571838379, "train/lr": 2.0000000000000002e-07, "train/mfu": 0.029959478654027243, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 5, "data": {"train/loss": 1.4234269857406616, "train/grad_norm": 22.885927200317383, "train/lr": 2.5000000000000004e-07, "train/mfu": 0.03041228951712963, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 6, "data": {"train/loss": 1.3694987297058105, "train/grad_norm": 20.738956451416016, "train/lr": 3.0000000000000004e-07, "train/mfu": 0.030652396461812524, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 7, "data": {"train/loss": 1.3781254291534424, "train/grad_norm": 22.311016082763672, "train/lr": 3.5000000000000004e-07, "train/mfu": 0.030611869280525172, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 8, "data": {"train/loss": 1.369199275970459, "train/grad_norm": 22.689287185668945, "train/lr": 4.0000000000000003e-07, "train/mfu": 0.030545990103126672, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 9, "data": {"train/loss": 1.33571457862854, "train/grad_norm": 22.287456512451172, "train/lr": 4.5000000000000003e-07, "train/mfu": 0.03047368180250765, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 10, "data": {"train/loss": 1.43898606300354, "train/grad_norm": 23.256399154663086, "train/lr": 5.000000000000001e-07, "train/mfu": 0.030399099736581083, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 11, "data": {"train/loss": 1.3927096128463745, "train/grad_norm": 20.957683563232422, "train/lr": 5.5e-07, "train/mfu": 0.03065323648088853, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 12, "data": {"train/loss": 1.3783824443817139, "train/grad_norm": 21.3725643157959, "train/lr": 6.000000000000001e-07, "train/mfu": 0.030713156064842054, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 13, "data": {"train/loss": 1.360546588897705, "train/grad_norm": 20.78483772277832, "train/lr": 6.5e-07, "train/mfu": 0.030572867130492457, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 14, "data": {"train/loss": 1.3519256114959717, "train/grad_norm": 19.4432430267334, "train/lr": 7.000000000000001e-07, "train/mfu": 0.030742865028169395, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 15, "data": {"train/loss": 1.326566457748413, "train/grad_norm": 19.5163631439209, "train/lr": 7.5e-07, "train/mfu": 0.0305415372482093, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 16, "data": {"train/loss": 1.2699073553085327, "train/grad_norm": 17.31005859375, "train/lr": 8.000000000000001e-07, "train/mfu": 0.030721690142735392, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 17, "data": {"train/loss": 1.3421967029571533, "train/grad_norm": 18.33091926574707, "train/lr": 8.500000000000001e-07, "train/mfu": 0.031065469222381733, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 18, "data": {"train/loss": 1.2838574647903442, "train/grad_norm": 17.2744140625, "train/lr": 9.000000000000001e-07, "train/mfu": 0.030602700221453772, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 19, "data": {"train/loss": 1.2859405279159546, "train/grad_norm": 19.00152015686035, "train/lr": 9.500000000000001e-07, "train/mfu": 0.030380901388213297, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 20, "data": {"train/loss": 1.1771923303604126, "train/grad_norm": 16.300601959228516, "train/lr": 1.0000000000000002e-06, "train/mfu": 0.031162381890917384, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 21, "data": {"train/loss": 1.1847703456878662, "train/grad_norm": 16.404748916625977, "train/lr": 1.0500000000000001e-06, "train/mfu": 0.03104894632559423, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 22, "data": {"train/loss": 1.1499940156936646, "train/grad_norm": 15.843612670898438, "train/lr": 1.1e-06, "train/mfu": 0.030561008552817927, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 23, "data": {"train/loss": 1.1221171617507935, "train/grad_norm": 16.228199005126953, "train/lr": 1.1500000000000002e-06, "train/mfu": 0.030731104830047092, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 24, "data": {"train/loss": 1.12303626537323, "train/grad_norm": 16.546581268310547, "train/lr": 1.2000000000000002e-06, "train/mfu": 0.030594131557509417, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 25, "data": {"train/loss": 1.162789225578308, "train/grad_norm": 19.07337188720703, "train/lr": 1.25e-06, "train/mfu": 0.030413365710346193, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 26, "data": {"train/loss": 1.0560481548309326, "train/grad_norm": 17.774614334106445, "train/lr": 1.3e-06, "train/mfu": 0.03073790757039046, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 27, "data": {"train/loss": 0.9023480415344238, "train/grad_norm": 10.733846664428711, "train/lr": 1.3500000000000002e-06, "train/mfu": 0.03093587497778809, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 28, "data": {"train/loss": 0.8743671178817749, "train/grad_norm": 10.118925094604492, "train/lr": 1.4000000000000001e-06, "train/mfu": 0.030636743205189013, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 29, "data": {"train/loss": 0.8669190406799316, "train/grad_norm": 9.848087310791016, "train/lr": 1.45e-06, "train/mfu": 0.030634350141001066, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 30, "data": {"train/loss": 0.8446913957595825, "train/grad_norm": 10.094405174255371, "train/lr": 1.5e-06, "train/mfu": 0.030847890989680334, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 31, "data": {"train/loss": 0.7950286865234375, "train/grad_norm": 9.25986385345459, "train/lr": 1.5500000000000002e-06, "train/mfu": 0.030766057692230394, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 32, "data": {"train/loss": 0.829530656337738, "train/grad_norm": 8.885040283203125, "train/lr": 1.6000000000000001e-06, "train/mfu": 0.0301692083077552, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 33, "data": {"train/loss": 0.8438612222671509, "train/grad_norm": 8.718247413635254, "train/lr": 1.6500000000000003e-06, "train/mfu": 0.030291415314512862, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 34, "data": {"train/loss": 0.748971164226532, "train/grad_norm": 8.447968482971191, "train/lr": 1.7000000000000002e-06, "train/mfu": 0.030175856515616974, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 35, "data": {"train/loss": 0.7234981060028076, "train/grad_norm": 7.458281517028809, "train/lr": 1.75e-06, "train/mfu": 0.03053519336524536, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 36, "data": {"train/loss": 0.7254950404167175, "train/grad_norm": 6.30449104309082, "train/lr": 1.8000000000000001e-06, "train/mfu": 0.030732295186992286, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 37, "data": {"train/loss": 0.6604161858558655, "train/grad_norm": 5.700966835021973, "train/lr": 1.85e-06, "train/mfu": 0.03029139684945152, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 38, "data": {"train/loss": 0.668705940246582, "train/grad_norm": 5.871653079986572, "train/lr": 1.9000000000000002e-06, "train/mfu": 0.030347131731358713, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 39, "data": {"train/loss": 0.6414984464645386, "train/grad_norm": 6.137818336486816, "train/lr": 1.9500000000000004e-06, "train/mfu": 0.030265485140921748, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 40, "data": {"train/loss": 0.6111752986907959, "train/grad_norm": 5.2909040451049805, "train/lr": 2.0000000000000003e-06, "train/mfu": 0.03021761766522324, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 41, "data": {"train/loss": 0.5905518531799316, "train/grad_norm": 4.7470808029174805, "train/lr": 2.05e-06, "train/mfu": 0.030368278341947556, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 42, "data": {"train/loss": 0.5549130439758301, "train/grad_norm": 3.5258634090423584, "train/lr": 2.1000000000000002e-06, "train/mfu": 0.03033336913164543, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 43, "data": {"train/loss": 0.5736464262008667, "train/grad_norm": 3.006542921066284, "train/lr": 2.15e-06, "train/mfu": 0.030584058590782007, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 44, "data": {"train/loss": 0.6455510854721069, "train/grad_norm": 2.998359203338623, "train/lr": 2.2e-06, "train/mfu": 0.030574370575317446, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 45, "data": {"train/loss": 0.595054030418396, "train/grad_norm": 2.7914979457855225, "train/lr": 2.25e-06, "train/mfu": 0.03051220079322323, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 46, "data": {"train/loss": 0.5680330991744995, "train/grad_norm": 2.5681769847869873, "train/lr": 2.3000000000000004e-06, "train/mfu": 0.02978043224508836, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 47, "data": {"train/loss": 0.5191160440444946, "train/grad_norm": 2.2849042415618896, "train/lr": 2.35e-06, "train/mfu": 0.03021687201995397, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 48, "data": {"train/loss": 0.563428521156311, "train/grad_norm": 2.3016273975372314, "train/lr": 2.4000000000000003e-06, "train/mfu": 0.03031148604296443, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 49, "data": {"train/loss": 0.511555552482605, "train/grad_norm": 2.401689052581787, "train/lr": 2.4500000000000003e-06, "train/mfu": 0.030309666529101813, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 50, "data": {"train/loss": 0.599455714225769, "train/grad_norm": 2.264103889465332, "train/lr": 2.5e-06, "train/mfu": 0.030515564178783018, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 51, "data": {"train/loss": 0.5330228209495544, "train/grad_norm": 2.103518009185791, "train/lr": 2.55e-06, "train/mfu": 0.030501917113601933, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 52, "data": {"train/loss": 0.5174040794372559, "train/grad_norm": 2.408111333847046, "train/lr": 2.6e-06, "train/mfu": 0.03030861702487124, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 53, "data": {"train/loss": 0.5456167459487915, "train/grad_norm": 2.140928268432617, "train/lr": 2.6500000000000005e-06, "train/mfu": 0.03034929197656727, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 54, "data": {"train/loss": 0.5342966318130493, "train/grad_norm": 2.181791305541992, "train/lr": 2.7000000000000004e-06, "train/mfu": 0.03055307085292286, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 55, "data": {"train/loss": 0.527019202709198, "train/grad_norm": 2.0864710807800293, "train/lr": 2.7500000000000004e-06, "train/mfu": 0.03057755151726606, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 56, "data": {"train/loss": 0.5215409994125366, "train/grad_norm": 2.085679054260254, "train/lr": 2.8000000000000003e-06, "train/mfu": 0.03014353324559057, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 57, "data": {"train/loss": 0.48290321230888367, "train/grad_norm": 2.0086963176727295, "train/lr": 2.85e-06, "train/mfu": 0.030263181058841866, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 58, "data": {"train/loss": 0.5301523208618164, "train/grad_norm": 1.7890490293502808, "train/lr": 2.9e-06, "train/mfu": 0.030621488176128538, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 58, "data": {"val/loss": 0.5348434448242188}}
{"step": 59, "data": {"train/loss": 0.5066267251968384, "train/grad_norm": 1.9155874252319336, "train/lr": 2.95e-06, "train/mfu": 0.030023010312630778, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 60, "data": {"train/loss": 0.4981371760368347, "train/grad_norm": 1.7024860382080078, "train/lr": 3e-06, "train/mfu": 0.030062240573302354, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 61, "data": {"train/loss": 0.49525195360183716, "train/grad_norm": 1.6483858823776245, "train/lr": 3.05e-06, "train/mfu": 0.03075299804271652, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 62, "data": {"train/loss": 0.4814748466014862, "train/grad_norm": 1.7512726783752441, "train/lr": 3.1000000000000004e-06, "train/mfu": 0.030689218209251135, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 63, "data": {"train/loss": 0.5114071369171143, "train/grad_norm": 1.6742594242095947, "train/lr": 3.1500000000000003e-06, "train/mfu": 0.030057041461603477, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 64, "data": {"train/loss": 0.4892873466014862, "train/grad_norm": 1.6192888021469116, "train/lr": 3.2000000000000003e-06, "train/mfu": 0.030169858086872822, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 65, "data": {"train/loss": 0.4603148400783539, "train/grad_norm": 1.7280349731445312, "train/lr": 3.2500000000000002e-06, "train/mfu": 0.03068030384336897, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 66, "data": {"train/loss": 0.4769144058227539, "train/grad_norm": 1.5291913747787476, "train/lr": 3.3000000000000006e-06, "train/mfu": 0.030240103804626536, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 67, "data": {"train/loss": 0.46281546354293823, "train/grad_norm": 1.5449358224868774, "train/lr": 3.3500000000000005e-06, "train/mfu": 0.030138303134527096, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 68, "data": {"train/loss": 0.4961838126182556, "train/grad_norm": 1.6702994108200073, "train/lr": 3.4000000000000005e-06, "train/mfu": 0.030439931586129447, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 69, "data": {"train/loss": 0.48854708671569824, "train/grad_norm": 1.5742803812026978, "train/lr": 3.45e-06, "train/mfu": 0.030331896383281178, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 70, "data": {"train/loss": 0.45035046339035034, "train/grad_norm": 1.5209639072418213, "train/lr": 3.5e-06, "train/mfu": 0.030315661497582982, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 71, "data": {"train/loss": 0.4711051285266876, "train/grad_norm": 1.6153515577316284, "train/lr": 3.5500000000000003e-06, "train/mfu": 0.03046528617404493, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 72, "data": {"train/loss": 0.48085668683052063, "train/grad_norm": 1.6570242643356323, "train/lr": 3.6000000000000003e-06, "train/mfu": 0.030319962422950257, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 73, "data": {"train/loss": 0.46162867546081543, "train/grad_norm": 1.6630200147628784, "train/lr": 3.65e-06, "train/mfu": 0.030173261560469785, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 74, "data": {"train/loss": 0.4552306532859802, "train/grad_norm": 1.5823243856430054, "train/lr": 3.7e-06, "train/mfu": 0.030580067040850752, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 75, "data": {"train/loss": 0.46328163146972656, "train/grad_norm": 1.5723007917404175, "train/lr": 3.7500000000000005e-06, "train/mfu": 0.03067439349576403, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 76, "data": {"train/loss": 0.49877023696899414, "train/grad_norm": 1.623632550239563, "train/lr": 3.8000000000000005e-06, "train/mfu": 0.030406678282891356, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 77, "data": {"train/loss": 0.43048083782196045, "train/grad_norm": 1.4696086645126343, "train/lr": 3.85e-06, "train/mfu": 0.03038680110642464, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 78, "data": {"train/loss": 0.4466569423675537, "train/grad_norm": 1.499531626701355, "train/lr": 3.900000000000001e-06, "train/mfu": 0.030674748166968777, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 79, "data": {"train/loss": 0.47631898522377014, "train/grad_norm": 1.6034578084945679, "train/lr": 3.95e-06, "train/mfu": 0.03064493025723891, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 80, "data": {"train/loss": 0.4705894887447357, "train/grad_norm": 1.524366855621338, "train/lr": 4.000000000000001e-06, "train/mfu": 0.030401160626872824, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 81, "data": {"train/loss": 0.49524953961372375, "train/grad_norm": 1.5291991233825684, "train/lr": 4.05e-06, "train/mfu": 0.03053118257567058, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 82, "data": {"train/loss": 0.46792179346084595, "train/grad_norm": 1.5889930725097656, "train/lr": 4.1e-06, "train/mfu": 0.030079398709026473, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 83, "data": {"train/loss": 0.4469946622848511, "train/grad_norm": 1.4875051975250244, "train/lr": 4.15e-06, "train/mfu": 0.030448663152118586, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 84, "data": {"train/loss": 0.45111727714538574, "train/grad_norm": 1.4659117460250854, "train/lr": 4.2000000000000004e-06, "train/mfu": 0.030674352719157683, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 85, "data": {"train/loss": 0.4899555742740631, "train/grad_norm": 1.7941234111785889, "train/lr": 4.25e-06, "train/mfu": 0.030408342369783944, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 86, "data": {"train/loss": 0.46326470375061035, "train/grad_norm": 1.5693249702453613, "train/lr": 4.3e-06, "train/mfu": 0.030415829835779448, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 87, "data": {"train/loss": 0.45111966133117676, "train/grad_norm": 1.5972007513046265, "train/lr": 4.350000000000001e-06, "train/mfu": 0.030437148837797176, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 88, "data": {"train/loss": 0.4675295054912567, "train/grad_norm": 1.6223044395446777, "train/lr": 4.4e-06, "train/mfu": 0.03065231652447232, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 89, "data": {"train/loss": 0.47998303174972534, "train/grad_norm": 1.5762286186218262, "train/lr": 4.450000000000001e-06, "train/mfu": 0.030323337382833, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 90, "data": {"train/loss": 0.4713902771472931, "train/grad_norm": 1.6824896335601807, "train/lr": 4.5e-06, "train/mfu": 0.03031339286912679, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 91, "data": {"train/loss": 0.44212496280670166, "train/grad_norm": 1.5407607555389404, "train/lr": 4.5500000000000005e-06, "train/mfu": 0.03056221891209342, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 92, "data": {"train/loss": 0.4686926603317261, "train/grad_norm": 1.581063985824585, "train/lr": 4.600000000000001e-06, "train/mfu": 0.030456970503307472, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 93, "data": {"train/loss": 0.47227081656455994, "train/grad_norm": 1.4839907884597778, "train/lr": 4.65e-06, "train/mfu": 0.03008968017900786, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 94, "data": {"train/loss": 0.45586785674095154, "train/grad_norm": 1.4325131177902222, "train/lr": 4.7e-06, "train/mfu": 0.030313980332486216, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 95, "data": {"train/loss": 0.47075122594833374, "train/grad_norm": 1.5842547416687012, "train/lr": 4.75e-06, "train/mfu": 0.030599401860318436, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 96, "data": {"train/loss": 0.4718068540096283, "train/grad_norm": 1.4509506225585938, "train/lr": 4.800000000000001e-06, "train/mfu": 0.030450904659876262, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 97, "data": {"train/loss": 0.47390127182006836, "train/grad_norm": 1.553842544555664, "train/lr": 4.85e-06, "train/mfu": 0.03031160372098676, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 98, "data": {"train/loss": 0.4233379065990448, "train/grad_norm": 1.5049641132354736, "train/lr": 4.9000000000000005e-06, "train/mfu": 0.030365447345932172, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 99, "data": {"train/loss": 0.5002405643463135, "train/grad_norm": 1.4888603687286377, "train/lr": 4.95e-06, "train/mfu": 0.030597850520977573, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 100, "data": {"train/loss": 0.4506918787956238, "train/grad_norm": 1.4632817506790161, "train/lr": 5e-06, "train/mfu": 0.030413367013332585, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 101, "data": {"train/loss": 0.42498448491096497, "train/grad_norm": 1.416364073753357, "train/lr": 5.050000000000001e-06, "train/mfu": 0.030380653908506992, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 102, "data": {"train/loss": 0.5041759610176086, "train/grad_norm": 1.6927436590194702, "train/lr": 5.1e-06, "train/mfu": 0.03055663442692017, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 103, "data": {"train/loss": 0.448276162147522, "train/grad_norm": 1.5402847528457642, "train/lr": 5.150000000000001e-06, "train/mfu": 0.030239466223953498, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 104, "data": {"train/loss": 0.4531310200691223, "train/grad_norm": 1.4494329690933228, "train/lr": 5.2e-06, "train/mfu": 0.030552484951161127, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 105, "data": {"train/loss": 0.4302889108657837, "train/grad_norm": 1.4320391416549683, "train/lr": 5.2500000000000006e-06, "train/mfu": 0.030250631670761273, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 106, "data": {"train/loss": 0.43980395793914795, "train/grad_norm": 2.218139886856079, "train/lr": 5.300000000000001e-06, "train/mfu": 0.030201317452859085, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 107, "data": {"train/loss": 0.448339581489563, "train/grad_norm": 1.5320343971252441, "train/lr": 5.3500000000000004e-06, "train/mfu": 0.030089017430582125, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 108, "data": {"train/loss": 0.4636656641960144, "train/grad_norm": 1.4656271934509277, "train/lr": 5.400000000000001e-06, "train/mfu": 0.03030477445795622, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 109, "data": {"train/loss": 0.4304148554801941, "train/grad_norm": 1.4268286228179932, "train/lr": 5.450000000000001e-06, "train/mfu": 0.030288388995487837, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 110, "data": {"train/loss": 0.45622432231903076, "train/grad_norm": 1.5041980743408203, "train/lr": 5.500000000000001e-06, "train/mfu": 0.03007128904963018, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 111, "data": {"train/loss": 0.4376286268234253, "train/grad_norm": 1.4664251804351807, "train/lr": 5.550000000000001e-06, "train/mfu": 0.030309989372220326, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 112, "data": {"train/loss": 0.4424520432949066, "train/grad_norm": 1.4875332117080688, "train/lr": 5.600000000000001e-06, "train/mfu": 0.030559305277429106, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 113, "data": {"train/loss": 0.41592517495155334, "train/grad_norm": 1.2957267761230469, "train/lr": 5.65e-06, "train/mfu": 0.030092538436173336, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 114, "data": {"train/loss": 0.4759266972541809, "train/grad_norm": 1.5157291889190674, "train/lr": 5.7e-06, "train/mfu": 0.03011431487623879, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 115, "data": {"train/loss": 0.4751152992248535, "train/grad_norm": 1.5426924228668213, "train/lr": 5.75e-06, "train/mfu": 0.030516332615375605, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 116, "data": {"train/loss": 0.4846228063106537, "train/grad_norm": 1.4943634271621704, "train/lr": 5.8e-06, "train/mfu": 0.03010884227735658, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 116, "data": {"val/loss": 0.4675496220588684}}
