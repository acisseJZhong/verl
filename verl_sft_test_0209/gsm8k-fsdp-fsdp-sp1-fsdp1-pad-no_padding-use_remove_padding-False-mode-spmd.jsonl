{"step": 1, "data": {"train/loss": 1.371269702911377, "train/grad_norm": 22.434001922607422, "train/lr": 2.5000000000000004e-07, "train/mfu": 0.020095068030192516, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 2, "data": {"train/loss": 1.4285786151885986, "train/grad_norm": 22.004255294799805, "train/lr": 5.000000000000001e-07, "train/mfu": 0.022652451576148487, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 3, "data": {"train/loss": 1.3438763618469238, "train/grad_norm": 21.265045166015625, "train/lr": 7.5e-07, "train/mfu": 0.02289532526156469, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 4, "data": {"train/loss": 1.3838849067687988, "train/grad_norm": 21.39470863342285, "train/lr": 1.0000000000000002e-06, "train/mfu": 0.02254656259838711, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 5, "data": {"train/loss": 1.4175801277160645, "train/grad_norm": 22.484920501708984, "train/lr": 1.25e-06, "train/mfu": 0.022325141960994065, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 6, "data": {"train/loss": 1.3530117273330688, "train/grad_norm": 19.821767807006836, "train/lr": 1.5e-06, "train/mfu": 0.022767315435660417, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 7, "data": {"train/loss": 1.3560945987701416, "train/grad_norm": 21.227827072143555, "train/lr": 1.75e-06, "train/mfu": 0.022988000348561684, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 8, "data": {"train/loss": 1.3030158281326294, "train/grad_norm": 19.099016189575195, "train/lr": 2.0000000000000003e-06, "train/mfu": 0.02283125704768346, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 9, "data": {"train/loss": 1.2587716579437256, "train/grad_norm": 17.566049575805664, "train/lr": 2.25e-06, "train/mfu": 0.022732764514947948, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 10, "data": {"train/loss": 1.2488386631011963, "train/grad_norm": 16.676170349121094, "train/lr": 2.5e-06, "train/mfu": 0.02275270812788847, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 11, "data": {"train/loss": 1.20989990234375, "train/grad_norm": 15.880334854125977, "train/lr": 2.7500000000000004e-06, "train/mfu": 0.022734546142037237, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 12, "data": {"train/loss": 1.153289556503296, "train/grad_norm": 16.80778694152832, "train/lr": 3e-06, "train/mfu": 0.022490229098977903, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 13, "data": {"train/loss": 0.9115527868270874, "train/grad_norm": 11.65619945526123, "train/lr": 3.2500000000000002e-06, "train/mfu": 0.022871459462346984, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 14, "data": {"train/loss": 0.8916317820549011, "train/grad_norm": 10.35766887664795, "train/lr": 3.5e-06, "train/mfu": 0.023046348661465342, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 15, "data": {"train/loss": 0.8341829776763916, "train/grad_norm": 10.299408912658691, "train/lr": 3.7500000000000005e-06, "train/mfu": 0.022396493110958964, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 16, "data": {"train/loss": 0.7916869521141052, "train/grad_norm": 8.447111129760742, "train/lr": 4.000000000000001e-06, "train/mfu": 0.02261927437655956, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 17, "data": {"train/loss": 0.8129979372024536, "train/grad_norm": 8.594613075256348, "train/lr": 4.25e-06, "train/mfu": 0.023072819115585372, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 18, "data": {"train/loss": 0.6822352409362793, "train/grad_norm": 6.801041603088379, "train/lr": 4.5e-06, "train/mfu": 0.02262294772703121, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 19, "data": {"train/loss": 0.6323468685150146, "train/grad_norm": 6.646197319030762, "train/lr": 4.75e-06, "train/mfu": 0.02251820545472688, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 20, "data": {"train/loss": 0.6088073253631592, "train/grad_norm": 4.731354713439941, "train/lr": 5e-06, "train/mfu": 0.022353439768336723, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 21, "data": {"train/loss": 0.5955283641815186, "train/grad_norm": 3.4845926761627197, "train/lr": 5.2500000000000006e-06, "train/mfu": 0.02324841577533614, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 22, "data": {"train/loss": 0.5777586698532104, "train/grad_norm": 2.8527164459228516, "train/lr": 5.500000000000001e-06, "train/mfu": 0.02291492074510214, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 23, "data": {"train/loss": 0.5572372674942017, "train/grad_norm": 2.5853021144866943, "train/lr": 5.75e-06, "train/mfu": 0.0228854509511048, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 24, "data": {"train/loss": 0.5637984871864319, "train/grad_norm": 2.2517638206481934, "train/lr": 6e-06, "train/mfu": 0.023048478846763976, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 25, "data": {"train/loss": 0.5347636938095093, "train/grad_norm": 2.456022262573242, "train/lr": 6.25e-06, "train/mfu": 0.022227584485871102, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 26, "data": {"train/loss": 0.5297735929489136, "train/grad_norm": 2.4906139373779297, "train/lr": 6.5000000000000004e-06, "train/mfu": 0.021260825026056633, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 27, "data": {"train/loss": 0.5248017311096191, "train/grad_norm": 2.363910436630249, "train/lr": 6.750000000000001e-06, "train/mfu": 0.015424168954110262, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 28, "data": {"train/loss": 0.5288630723953247, "train/grad_norm": 2.1143791675567627, "train/lr": 7e-06, "train/mfu": 0.013452544613867794, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 29, "data": {"train/loss": 0.538033127784729, "train/grad_norm": 1.9451394081115723, "train/lr": 7.25e-06, "train/mfu": 0.012821355874583528, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 30, "data": {"train/loss": 0.4983367621898651, "train/grad_norm": 1.944507122039795, "train/lr": 7.500000000000001e-06, "train/mfu": 0.013029990551498116, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 31, "data": {"train/loss": 0.4742942452430725, "train/grad_norm": 1.623689889907837, "train/lr": 7.75e-06, "train/mfu": 0.013377096538869808, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 32, "data": {"train/loss": 0.5212438106536865, "train/grad_norm": 1.7424551248550415, "train/lr": 8.000000000000001e-06, "train/mfu": 0.012605599168900552, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 33, "data": {"train/loss": 0.5387812256813049, "train/grad_norm": 1.838100552558899, "train/lr": 8.25e-06, "train/mfu": 0.012702690035489444, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 34, "data": {"train/loss": 0.4647584855556488, "train/grad_norm": 1.7781792879104614, "train/lr": 8.5e-06, "train/mfu": 0.012621787986600476, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 35, "data": {"train/loss": 0.45881712436676025, "train/grad_norm": 1.5772026777267456, "train/lr": 8.750000000000001e-06, "train/mfu": 0.012727251511094993, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 36, "data": {"train/loss": 0.47274699807167053, "train/grad_norm": 1.6185939311981201, "train/lr": 9e-06, "train/mfu": 0.012910805016383867, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 37, "data": {"train/loss": 0.46620020270347595, "train/grad_norm": 1.6613024473190308, "train/lr": 9.250000000000001e-06, "train/mfu": 0.013027600076516316, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 38, "data": {"train/loss": 0.49559110403060913, "train/grad_norm": 1.6760088205337524, "train/lr": 9.5e-06, "train/mfu": 0.013462494059587306, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 39, "data": {"train/loss": 0.48242413997650146, "train/grad_norm": 1.4906376600265503, "train/lr": 9.75e-06, "train/mfu": 0.012453335933377612, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 40, "data": {"train/loss": 0.4663000702857971, "train/grad_norm": 1.5117594003677368, "train/lr": 1e-05, "train/mfu": 0.012487833596675426, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 41, "data": {"train/loss": 0.4642408788204193, "train/grad_norm": 1.52318274974823, "train/lr": 9.999132582169293e-06, "train/mfu": 0.013535619752311183, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 42, "data": {"train/loss": 0.4404222071170807, "train/grad_norm": 1.4800704717636108, "train/lr": 9.996530663083255e-06, "train/mfu": 0.012771978059800586, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 43, "data": {"train/loss": 0.46444156765937805, "train/grad_norm": 1.3679757118225098, "train/lr": 9.992195245831223e-06, "train/mfu": 0.012874362588988369, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 44, "data": {"train/loss": 0.5360382795333862, "train/grad_norm": 1.498131275177002, "train/lr": 9.986128001799077e-06, "train/mfu": 0.012949288261039194, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 45, "data": {"train/loss": 0.48316940665245056, "train/grad_norm": 1.4295001029968262, "train/lr": 9.978331270024888e-06, "train/mfu": 0.012881245694284067, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 46, "data": {"train/loss": 0.4701389670372009, "train/grad_norm": 1.4379462003707886, "train/lr": 9.96880805629717e-06, "train/mfu": 0.012663276384866917, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 47, "data": {"train/loss": 0.43259257078170776, "train/grad_norm": 1.5157159566879272, "train/lr": 9.957562031996099e-06, "train/mfu": 0.01306250752145713, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 48, "data": {"train/loss": 0.4716830551624298, "train/grad_norm": 1.421044945716858, "train/lr": 9.944597532678122e-06, "train/mfu": 0.012995561442426463, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 49, "data": {"train/loss": 0.42293214797973633, "train/grad_norm": 1.5351365804672241, "train/lr": 9.929919556404513e-06, "train/mfu": 0.01469663110312267, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 50, "data": {"train/loss": 0.5135331153869629, "train/grad_norm": 1.535095453262329, "train/lr": 9.913533761814537e-06, "train/mfu": 0.022816325812744398, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 51, "data": {"train/loss": 0.4535878598690033, "train/grad_norm": 1.3950666189193726, "train/lr": 9.895446465943928e-06, "train/mfu": 0.023159617897573134, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 52, "data": {"train/loss": 0.43981435894966125, "train/grad_norm": 1.359106183052063, "train/lr": 9.875664641789547e-06, "train/mfu": 0.022659718116308673, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 53, "data": {"train/loss": 0.4690209627151489, "train/grad_norm": 1.577997088432312, "train/lr": 9.85419591562117e-06, "train/mfu": 0.022857773946452727, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 54, "data": {"train/loss": 0.4669297933578491, "train/grad_norm": 1.532617211341858, "train/lr": 9.831048564041414e-06, "train/mfu": 0.022937917067336916, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 55, "data": {"train/loss": 0.4588271379470825, "train/grad_norm": 1.415792465209961, "train/lr": 9.80623151079494e-06, "train/mfu": 0.023124971639147725, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 56, "data": {"train/loss": 0.452413946390152, "train/grad_norm": 1.4397621154785156, "train/lr": 9.779754323328192e-06, "train/mfu": 0.022660151147113772, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 57, "data": {"train/loss": 0.41746848821640015, "train/grad_norm": 1.4200372695922852, "train/lr": 9.751627209100953e-06, "train/mfu": 0.022696872723677743, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 58, "data": {"train/loss": 0.4704992175102234, "train/grad_norm": 1.4281522035598755, "train/lr": 9.72186101165118e-06, "train/mfu": 0.023135934330163022, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 58, "data": {"val/loss": 0.4691604673862457}}
{"step": 59, "data": {"train/loss": 0.41561949253082275, "train/grad_norm": 1.3286879062652588, "train/lr": 9.690467206414617e-06, "train/mfu": 0.022742843691790034, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 60, "data": {"train/loss": 0.4267484247684479, "train/grad_norm": 1.2753695249557495, "train/lr": 9.65745789630079e-06, "train/mfu": 0.022575373053474585, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 61, "data": {"train/loss": 0.4138578176498413, "train/grad_norm": 1.25570809841156, "train/lr": 9.622845807027112e-06, "train/mfu": 0.023230352191824528, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 62, "data": {"train/loss": 0.4066656231880188, "train/grad_norm": 1.3239928483963013, "train/lr": 9.586644282212866e-06, "train/mfu": 0.023146699972540583, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 63, "data": {"train/loss": 0.428252637386322, "train/grad_norm": 1.3850477933883667, "train/lr": 9.548867278235e-06, "train/mfu": 0.02240941362603206, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 64, "data": {"train/loss": 0.41227227449417114, "train/grad_norm": 1.2770745754241943, "train/lr": 9.509529358847657e-06, "train/mfu": 0.021300487253713737, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 65, "data": {"train/loss": 0.38598525524139404, "train/grad_norm": 1.3915126323699951, "train/lr": 9.468645689567599e-06, "train/mfu": 0.020552074259884746, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 66, "data": {"train/loss": 0.39892545342445374, "train/grad_norm": 1.3166565895080566, "train/lr": 9.426232031827589e-06, "train/mfu": 0.01792076540330992, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 67, "data": {"train/loss": 0.395211786031723, "train/grad_norm": 1.411986231803894, "train/lr": 9.382304736900066e-06, "train/mfu": 0.015081823411731244, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 68, "data": {"train/loss": 0.41991961002349854, "train/grad_norm": 1.5494195222854614, "train/lr": 9.336880739593417e-06, "train/mfu": 0.01345589125566349, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 69, "data": {"train/loss": 0.41247254610061646, "train/grad_norm": 1.4709035158157349, "train/lr": 9.28997755172329e-06, "train/mfu": 0.013788988845264749, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 70, "data": {"train/loss": 0.37635043263435364, "train/grad_norm": 1.2965741157531738, "train/lr": 9.241613255361455e-06, "train/mfu": 0.013588847150186115, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 71, "data": {"train/loss": 0.39922183752059937, "train/grad_norm": 1.3917979001998901, "train/lr": 9.191806495864812e-06, "train/mfu": 0.013612535879346651, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 72, "data": {"train/loss": 0.40281301736831665, "train/grad_norm": 1.3681702613830566, "train/lr": 9.140576474687265e-06, "train/mfu": 0.013823344386664507, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 73, "data": {"train/loss": 0.3908989429473877, "train/grad_norm": 1.4418548345565796, "train/lr": 9.087942941977183e-06, "train/mfu": 0.013532027188986427, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 74, "data": {"train/loss": 0.37991270422935486, "train/grad_norm": 1.3709394931793213, "train/lr": 9.033926188963353e-06, "train/mfu": 0.01402552878057315, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 75, "data": {"train/loss": 0.40014350414276123, "train/grad_norm": 1.4550963640213013, "train/lr": 8.978547040132317e-06, "train/mfu": 0.013849628127242984, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 76, "data": {"train/loss": 0.42841094732284546, "train/grad_norm": 1.389119267463684, "train/lr": 8.921826845200142e-06, "train/mfu": 0.013847861250822333, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
