{"step": 1, "data": {"train/loss": 1.3710803985595703, "train/grad_norm": 22.640661239624023, "train/lr": 1.0000000000000001e-07, "train/mfu": 0.00900389299060556, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 2, "data": {"train/loss": 1.4284155368804932, "train/grad_norm": 22.18528175354004, "train/lr": 1.5000000000000002e-07, "train/mfu": 0.013384670647704665, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 3, "data": {"train/loss": 1.3432409763336182, "train/grad_norm": 21.398502349853516, "train/lr": 2.0000000000000002e-07, "train/mfu": 0.013587257485102968, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 4, "data": {"train/loss": 1.3845629692077637, "train/grad_norm": 21.591459274291992, "train/lr": 2.5000000000000004e-07, "train/mfu": 0.013275292838837468, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 5, "data": {"train/loss": 1.421494483947754, "train/grad_norm": 22.911314010620117, "train/lr": 3.0000000000000004e-07, "train/mfu": 0.01334664659268992, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 6, "data": {"train/loss": 1.369599461555481, "train/grad_norm": 20.783220291137695, "train/lr": 3.5000000000000004e-07, "train/mfu": 0.013420944367027836, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 7, "data": {"train/loss": 1.37474524974823, "train/grad_norm": 22.24884605407715, "train/lr": 4.0000000000000003e-07, "train/mfu": 0.013352196659932604, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 8, "data": {"train/loss": 1.3677115440368652, "train/grad_norm": 22.6768741607666, "train/lr": 4.5000000000000003e-07, "train/mfu": 0.013391797714152547, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 9, "data": {"train/loss": 1.3338631391525269, "train/grad_norm": 22.22542953491211, "train/lr": 5.000000000000001e-07, "train/mfu": 0.013414885404819145, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 10, "data": {"train/loss": 1.426544427871704, "train/grad_norm": 22.54629135131836, "train/lr": 5.5e-07, "train/mfu": 0.013369177813819192, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 11, "data": {"train/loss": 1.3914499282836914, "train/grad_norm": 20.969152450561523, "train/lr": 6.000000000000001e-07, "train/mfu": 0.013571774561951652, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 12, "data": {"train/loss": 1.3753447532653809, "train/grad_norm": 21.19864273071289, "train/lr": 6.5e-07, "train/mfu": 0.013608734772750068, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 13, "data": {"train/loss": 1.330481767654419, "train/grad_norm": 19.144184112548828, "train/lr": 7.000000000000001e-07, "train/mfu": 0.013461294733480497, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 14, "data": {"train/loss": 1.3422237634658813, "train/grad_norm": 18.855735778808594, "train/lr": 7.5e-07, "train/mfu": 0.013607108476305137, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 15, "data": {"train/loss": 1.3222405910491943, "train/grad_norm": 19.34272003173828, "train/lr": 8.000000000000001e-07, "train/mfu": 0.013509293877245195, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 16, "data": {"train/loss": 1.2612745761871338, "train/grad_norm": 16.897977828979492, "train/lr": 8.500000000000001e-07, "train/mfu": 0.01354521993870066, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 17, "data": {"train/loss": 1.338230848312378, "train/grad_norm": 18.173521041870117, "train/lr": 9.000000000000001e-07, "train/mfu": 0.013730382420388999, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 18, "data": {"train/loss": 1.2507829666137695, "train/grad_norm": 17.09989356994629, "train/lr": 9.500000000000001e-07, "train/mfu": 0.013553274110660901, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 19, "data": {"train/loss": 1.209700345993042, "train/grad_norm": 17.54894256591797, "train/lr": 1.0000000000000002e-06, "train/mfu": 0.013588625341982309, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 20, "data": {"train/loss": 1.1705116033554077, "train/grad_norm": 16.326736450195312, "train/lr": 1.0500000000000001e-06, "train/mfu": 0.01380115927543714, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 21, "data": {"train/loss": 1.1767964363098145, "train/grad_norm": 16.51018714904785, "train/lr": 1.1e-06, "train/mfu": 0.01373132928035387, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 22, "data": {"train/loss": 1.1338164806365967, "train/grad_norm": 16.138254165649414, "train/lr": 1.1500000000000002e-06, "train/mfu": 0.01352218019115181, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 23, "data": {"train/loss": 1.1072487831115723, "train/grad_norm": 16.450206756591797, "train/lr": 1.2000000000000002e-06, "train/mfu": 0.01357559060600912, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 24, "data": {"train/loss": 1.112816333770752, "train/grad_norm": 16.834707260131836, "train/lr": 1.25e-06, "train/mfu": 0.013590414127224181, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 25, "data": {"train/loss": 1.127814531326294, "train/grad_norm": 19.874446868896484, "train/lr": 1.3e-06, "train/mfu": 0.013459896177945869, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 26, "data": {"train/loss": 0.8839718103408813, "train/grad_norm": 10.008710861206055, "train/lr": 1.3500000000000002e-06, "train/mfu": 0.013558916813973417, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 27, "data": {"train/loss": 0.881052553653717, "train/grad_norm": 10.459495544433594, "train/lr": 1.4000000000000001e-06, "train/mfu": 0.013674716752040147, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 28, "data": {"train/loss": 0.8609613180160522, "train/grad_norm": 9.932330131530762, "train/lr": 1.45e-06, "train/mfu": 0.013595265486332211, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 29, "data": {"train/loss": 0.8527531623840332, "train/grad_norm": 9.627437591552734, "train/lr": 1.5e-06, "train/mfu": 0.013484387574645752, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 30, "data": {"train/loss": 0.8327146768569946, "train/grad_norm": 9.868081092834473, "train/lr": 1.5500000000000002e-06, "train/mfu": 0.013600658255842378, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 31, "data": {"train/loss": 0.7723116874694824, "train/grad_norm": 8.736133575439453, "train/lr": 1.6000000000000001e-06, "train/mfu": 0.01372344856402964, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 32, "data": {"train/loss": 0.8110690116882324, "train/grad_norm": 8.411637306213379, "train/lr": 1.6500000000000003e-06, "train/mfu": 0.013572604812654973, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 33, "data": {"train/loss": 0.8285468220710754, "train/grad_norm": 8.276798248291016, "train/lr": 1.7000000000000002e-06, "train/mfu": 0.013552601105148283, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 34, "data": {"train/loss": 0.7343951463699341, "train/grad_norm": 7.887701988220215, "train/lr": 1.75e-06, "train/mfu": 0.013497674175356383, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 35, "data": {"train/loss": 0.7005202174186707, "train/grad_norm": 6.3284687995910645, "train/lr": 1.8000000000000001e-06, "train/mfu": 0.013662650859715695, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 36, "data": {"train/loss": 0.6713690161705017, "train/grad_norm": 5.649715900421143, "train/lr": 1.85e-06, "train/mfu": 0.013735922814427485, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 37, "data": {"train/loss": 0.6313482522964478, "train/grad_norm": 5.792956352233887, "train/lr": 1.9000000000000002e-06, "train/mfu": 0.013549812038326442, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 38, "data": {"train/loss": 0.6480425596237183, "train/grad_norm": 5.831702709197998, "train/lr": 1.9500000000000004e-06, "train/mfu": 0.013612113616124816, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
0.0}}
