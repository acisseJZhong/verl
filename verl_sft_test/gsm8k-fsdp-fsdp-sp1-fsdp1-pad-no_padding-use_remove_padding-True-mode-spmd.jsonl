{"step": 1, "data": {"train/loss": 1.3715933561325073, "train/grad_norm": 22.431764602661133, "train/lr": 5.0000000000000004e-08, "train/mfu": 0.02157239790187369, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 2, "data": {"train/loss": 1.4289090633392334, "train/grad_norm": 22.014636993408203, "train/lr": 1.0000000000000001e-07, "train/mfu": 0.02403280879980733, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 3, "data": {"train/loss": 1.3440947532653809, "train/grad_norm": 21.283287048339844, "train/lr": 1.5000000000000002e-07, "train/mfu": 0.024357096483464256, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 4, "data": {"train/loss": 1.3846491575241089, "train/grad_norm": 21.410837173461914, "train/lr": 2.0000000000000002e-07, "train/mfu": 0.023865164470457487, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 5, "data": {"train/loss": 1.4219731092453003, "train/grad_norm": 22.732004165649414, "train/lr": 2.5000000000000004e-07, "train/mfu": 0.024010624506564864, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 6, "data": {"train/loss": 1.369738221168518, "train/grad_norm": 20.608850479125977, "train/lr": 3.0000000000000004e-07, "train/mfu": 0.024281215505166355, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 7, "data": {"train/loss": 1.3786966800689697, "train/grad_norm": 22.250852584838867, "train/lr": 3.5000000000000004e-07, "train/mfu": 0.02437722619017269, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 8, "data": {"train/loss": 1.3694555759429932, "train/grad_norm": 22.574573516845703, "train/lr": 4.0000000000000003e-07, "train/mfu": 0.024320798792178227, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 9, "data": {"train/loss": 1.335906744003296, "train/grad_norm": 22.064455032348633, "train/lr": 4.5000000000000003e-07, "train/mfu": 0.024147421368531423, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 10, "data": {"train/loss": 1.4398689270019531, "train/grad_norm": 23.05801773071289, "train/lr": 5.000000000000001e-07, "train/mfu": 0.024038227692559873, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 11, "data": {"train/loss": 1.393887996673584, "train/grad_norm": 20.837890625, "train/lr": 5.5e-07, "train/mfu": 0.02433674135152691, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 12, "data": {"train/loss": 1.380075454711914, "train/grad_norm": 21.26848793029785, "train/lr": 6.000000000000001e-07, "train/mfu": 0.02437692257763038, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 13, "data": {"train/loss": 1.3615983724594116, "train/grad_norm": 20.69782829284668, "train/lr": 6.5e-07, "train/mfu": 0.024212967654959127, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 14, "data": {"train/loss": 1.3533103466033936, "train/grad_norm": 19.220712661743164, "train/lr": 7.000000000000001e-07, "train/mfu": 0.02435280770213924, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 15, "data": {"train/loss": 1.3279600143432617, "train/grad_norm": 19.367874145507812, "train/lr": 7.5e-07, "train/mfu": 0.024119059577963658, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 16, "data": {"train/loss": 1.2710164785385132, "train/grad_norm": 17.203998565673828, "train/lr": 8.000000000000001e-07, "train/mfu": 0.024339525520834612, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 17, "data": {"train/loss": 1.3436753749847412, "train/grad_norm": 18.238985061645508, "train/lr": 8.500000000000001e-07, "train/mfu": 0.024638390104610594, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 18, "data": {"train/loss": 1.285698413848877, "train/grad_norm": 17.19182014465332, "train/lr": 9.000000000000001e-07, "train/mfu": 0.0243028013131357, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 19, "data": {"train/loss": 1.2885916233062744, "train/grad_norm": 18.859025955200195, "train/lr": 9.500000000000001e-07, "train/mfu": 0.02434549205130894, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 20, "data": {"train/loss": 1.1801354885101318, "train/grad_norm": 16.18413543701172, "train/lr": 1.0000000000000002e-06, "train/mfu": 0.02477597027112617, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 21, "data": {"train/loss": 1.1885178089141846, "train/grad_norm": 16.267929077148438, "train/lr": 1.0500000000000001e-06, "train/mfu": 0.02464609912321324, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 22, "data": {"train/loss": 1.1540162563323975, "train/grad_norm": 15.634798049926758, "train/lr": 1.1e-06, "train/mfu": 0.024189984436270493, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 23, "data": {"train/loss": 1.1258094310760498, "train/grad_norm": 15.996915817260742, "train/lr": 1.1500000000000002e-06, "train/mfu": 0.024323064046692492, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 24, "data": {"train/loss": 1.1265039443969727, "train/grad_norm": 16.203397750854492, "train/lr": 1.2000000000000002e-06, "train/mfu": 0.02436594703082442, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 25, "data": {"train/loss": 1.1668775081634521, "train/grad_norm": 18.784067153930664, "train/lr": 1.25e-06, "train/mfu": 0.024121229773146305, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 26, "data": {"train/loss": 1.0621650218963623, "train/grad_norm": 17.5768985748291, "train/lr": 1.3e-06, "train/mfu": 0.02435657699992233, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 27, "data": {"train/loss": 0.9031972885131836, "train/grad_norm": 10.826333999633789, "train/lr": 1.3500000000000002e-06, "train/mfu": 0.02451977741969924, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 28, "data": {"train/loss": 0.8750895857810974, "train/grad_norm": 10.154480934143066, "train/lr": 1.4000000000000001e-06, "train/mfu": 0.024339302083309044, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 29, "data": {"train/loss": 0.8679297566413879, "train/grad_norm": 9.902365684509277, "train/lr": 1.45e-06, "train/mfu": 0.024157498858899056, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 30, "data": {"train/loss": 0.8454810976982117, "train/grad_norm": 10.13793659210205, "train/lr": 1.5e-06, "train/mfu": 0.024487756872406913, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 31, "data": {"train/loss": 0.796523928642273, "train/grad_norm": 9.32671070098877, "train/lr": 1.5500000000000002e-06, "train/mfu": 0.024759989558816916, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 32, "data": {"train/loss": 0.8308395743370056, "train/grad_norm": 8.943648338317871, "train/lr": 1.6000000000000001e-06, "train/mfu": 0.024319046242407324, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 33, "data": {"train/loss": 0.8441179990768433, "train/grad_norm": 8.784411430358887, "train/lr": 1.6500000000000003e-06, "train/mfu": 0.024227631180760476, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 34, "data": {"train/loss": 0.7489649653434753, "train/grad_norm": 8.502776145935059, "train/lr": 1.7000000000000002e-06, "train/mfu": 0.024181199382969015, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 35, "data": {"train/loss": 0.7245672941207886, "train/grad_norm": 7.488917350769043, "train/lr": 1.75e-06, "train/mfu": 0.024430874668067724, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 36, "data": {"train/loss": 0.7257496118545532, "train/grad_norm": 6.278234958648682, "train/lr": 1.8000000000000001e-06, "train/mfu": 0.024723583771871414, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 37, "data": {"train/loss": 0.6612715125083923, "train/grad_norm": 5.725965976715088, "train/lr": 1.85e-06, "train/mfu": 0.024197730185626022, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 38, "data": {"train/loss": 0.6682080030441284, "train/grad_norm": 5.805703639984131, "train/lr": 1.9000000000000002e-06, "train/mfu": 0.024285784580177654, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 39, "data": {"train/loss": 0.641569197177887, "train/grad_norm": 6.166415691375732, "train/lr": 1.9500000000000004e-06, "train/mfu": 0.024299752249451332, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 40, "data": {"train/loss": 0.6112098693847656, "train/grad_norm": 5.32749605178833, "train/lr": 2.0000000000000003e-06, "train/mfu": 0.024193253831972145, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 41, "data": {"train/loss": 0.5902038812637329, "train/grad_norm": 4.7024407386779785, "train/lr": 2.05e-06, "train/mfu": 0.02433393286192028, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 42, "data": {"train/loss": 0.5547860860824585, "train/grad_norm": 3.541473865509033, "train/lr": 2.1000000000000002e-06, "train/mfu": 0.02431187497069704, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 43, "data": {"train/loss": 0.5738230347633362, "train/grad_norm": 3.0068347454071045, "train/lr": 2.15e-06, "train/mfu": 0.024564152722032388, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 44, "data": {"train/loss": 0.6452996730804443, "train/grad_norm": 2.9743735790252686, "train/lr": 2.2e-06, "train/mfu": 0.024500478180801612, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 45, "data": {"train/loss": 0.5950402021408081, "train/grad_norm": 2.843947649002075, "train/lr": 2.25e-06, "train/mfu": 0.024406492061763922, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 46, "data": {"train/loss": 0.568558394908905, "train/grad_norm": 2.583003044128418, "train/lr": 2.3000000000000004e-06, "train/mfu": 0.02349016595186761, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 47, "data": {"train/loss": 0.5195156335830688, "train/grad_norm": 2.295077085494995, "train/lr": 2.35e-06, "train/mfu": 0.02415853313934237, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 48, "data": {"train/loss": 0.5637872815132141, "train/grad_norm": 2.3333325386047363, "train/lr": 2.4000000000000003e-06, "train/mfu": 0.02417652662095627, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 49, "data": {"train/loss": 0.5115342140197754, "train/grad_norm": 2.4140336513519287, "train/lr": 2.4500000000000003e-06, "train/mfu": 0.024191990590463182, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 50, "data": {"train/loss": 0.5994061231613159, "train/grad_norm": 2.27443528175354, "train/lr": 2.5e-06, "train/mfu": 0.024395650746444657, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 51, "data": {"train/loss": 0.5332620739936829, "train/grad_norm": 2.109952926635742, "train/lr": 2.55e-06, "train/mfu": 0.024468207718349677, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 52, "data": {"train/loss": 0.5174912214279175, "train/grad_norm": 2.388593912124634, "train/lr": 2.6e-06, "train/mfu": 0.024277025177831677, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 53, "data": {"train/loss": 0.5455602407455444, "train/grad_norm": 2.129444122314453, "train/lr": 2.6500000000000005e-06, "train/mfu": 0.024278032604827776, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 54, "data": {"train/loss": 0.5348550081253052, "train/grad_norm": 2.2141425609588623, "train/lr": 2.7000000000000004e-06, "train/mfu": 0.024474660391915645, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 55, "data": {"train/loss": 0.5272574424743652, "train/grad_norm": 2.099236011505127, "train/lr": 2.7500000000000004e-06, "train/mfu": 0.02453435680285856, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 56, "data": {"train/loss": 0.5215773582458496, "train/grad_norm": 2.072228193283081, "train/lr": 2.8000000000000003e-06, "train/mfu": 0.024051836231582566, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 57, "data": {"train/loss": 0.4831765294075012, "train/grad_norm": 2.017437696456909, "train/lr": 2.85e-06, "train/mfu": 0.024205015533160186, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 58, "data": {"train/loss": 0.5307933688163757, "train/grad_norm": 1.799726128578186, "train/lr": 2.9e-06, "train/mfu": 0.024524311766553734, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 58, "data": {"val/loss": 0.5351342558860779}}
{"step": 59, "data": {"train/loss": 0.5069695115089417, "train/grad_norm": 1.9188817739486694, "train/lr": 2.95e-06, "train/mfu": 0.024094583682168543, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 60, "data": {"train/loss": 0.4983491897583008, "train/grad_norm": 1.7184488773345947, "train/lr": 3e-06, "train/mfu": 0.023993060056848193, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 61, "data": {"train/loss": 0.49543124437332153, "train/grad_norm": 1.6530362367630005, "train/lr": 3.05e-06, "train/mfu": 0.024676262347396866, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 62, "data": {"train/loss": 0.4818711280822754, "train/grad_norm": 1.7791953086853027, "train/lr": 3.1000000000000004e-06, "train/mfu": 0.024528129503094524, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 63, "data": {"train/loss": 0.5122075080871582, "train/grad_norm": 1.693686842918396, "train/lr": 3.1500000000000003e-06, "train/mfu": 0.02397869648950174, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 64, "data": {"train/loss": 0.48986899852752686, "train/grad_norm": 1.6382768154144287, "train/lr": 3.2000000000000003e-06, "train/mfu": 0.024137797494965196, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 65, "data": {"train/loss": 0.46033018827438354, "train/grad_norm": 1.7663357257843018, "train/lr": 3.2500000000000002e-06, "train/mfu": 0.024621127616434705, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 66, "data": {"train/loss": 0.4768458902835846, "train/grad_norm": 1.530410647392273, "train/lr": 3.3000000000000006e-06, "train/mfu": 0.02414288063478855, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 67, "data": {"train/loss": 0.463981568813324, "train/grad_norm": 1.5422922372817993, "train/lr": 3.3500000000000005e-06, "train/mfu": 0.024094060959107245, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 68, "data": {"train/loss": 0.4966815710067749, "train/grad_norm": 1.8292659521102905, "train/lr": 3.4000000000000005e-06, "train/mfu": 0.02436923108294216, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 69, "data": {"train/loss": 0.4887933135032654, "train/grad_norm": 1.5401643514633179, "train/lr": 3.45e-06, "train/mfu": 0.024309396971779775, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 70, "data": {"train/loss": 0.45061051845550537, "train/grad_norm": 1.5286914110183716, "train/lr": 3.5e-06, "train/mfu": 0.024195739799572118, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 71, "data": {"train/loss": 0.47118231654167175, "train/grad_norm": 1.6037951707839966, "train/lr": 3.5500000000000003e-06, "train/mfu": 0.02437399135977346, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 72, "data": {"train/loss": 0.48125216364860535, "train/grad_norm": 1.644451379776001, "train/lr": 3.6000000000000003e-06, "train/mfu": 0.02407035993637059, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 73, "data": {"train/loss": 0.46241092681884766, "train/grad_norm": 1.6562443971633911, "train/lr": 3.65e-06, "train/mfu": 0.024137617120998725, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 74, "data": {"train/loss": 0.4554379880428314, "train/grad_norm": 1.5759953260421753, "train/lr": 3.7e-06, "train/mfu": 0.024533793369104686, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 75, "data": {"train/loss": 0.46370336413383484, "train/grad_norm": 1.590136170387268, "train/lr": 3.7500000000000005e-06, "train/mfu": 0.024619607484329512, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 76, "data": {"train/loss": 0.499217689037323, "train/grad_norm": 1.7061762809753418, "train/lr": 3.8000000000000005e-06, "train/mfu": 0.02416267872074062, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 77, "data": {"train/loss": 0.4309428334236145, "train/grad_norm": 1.4481098651885986, "train/lr": 3.85e-06, "train/mfu": 0.02429003335596494, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 78, "data": {"train/loss": 0.44713497161865234, "train/grad_norm": 1.4899710416793823, "train/lr": 3.900000000000001e-06, "train/mfu": 0.024513300819016565, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 79, "data": {"train/loss": 0.47638189792633057, "train/grad_norm": 1.5905907154083252, "train/lr": 3.95e-06, "train/mfu": 0.024598833653028784, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 80, "data": {"train/loss": 0.47143658995628357, "train/grad_norm": 1.4953445196151733, "train/lr": 4.000000000000001e-06, "train/mfu": 0.024433658715326677, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 81, "data": {"train/loss": 0.4957761764526367, "train/grad_norm": 1.5411522388458252, "train/lr": 4.05e-06, "train/mfu": 0.024625772479630482, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 82, "data": {"train/loss": 0.4687430262565613, "train/grad_norm": 1.5530781745910645, "train/lr": 4.1e-06, "train/mfu": 0.024100384347087854, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 83, "data": {"train/loss": 0.44745492935180664, "train/grad_norm": 1.4764772653579712, "train/lr": 4.15e-06, "train/mfu": 0.024368529241972605, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 84, "data": {"train/loss": 0.45137274265289307, "train/grad_norm": 1.4507882595062256, "train/lr": 4.2000000000000004e-06, "train/mfu": 0.02465570009936084, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 85, "data": {"train/loss": 0.49049317836761475, "train/grad_norm": 1.80875563621521, "train/lr": 4.25e-06, "train/mfu": 0.024195283800741853, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 86, "data": {"train/loss": 0.46321865916252136, "train/grad_norm": 1.554384469985962, "train/lr": 4.3e-06, "train/mfu": 0.024279614129919247, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 87, "data": {"train/loss": 0.4498666822910309, "train/grad_norm": 1.5597177743911743, "train/lr": 4.350000000000001e-06, "train/mfu": 0.024345242820089895, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 88, "data": {"train/loss": 0.46756476163864136, "train/grad_norm": 1.5809719562530518, "train/lr": 4.4e-06, "train/mfu": 0.024570754828436837, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 89, "data": {"train/loss": 0.47991079092025757, "train/grad_norm": 1.585106372833252, "train/lr": 4.450000000000001e-06, "train/mfu": 0.024239594663477946, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 90, "data": {"train/loss": 0.47174420952796936, "train/grad_norm": 1.686423897743225, "train/lr": 4.5e-06, "train/mfu": 0.024189307208535748, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 91, "data": {"train/loss": 0.4419078230857849, "train/grad_norm": 1.526764988899231, "train/lr": 4.5500000000000005e-06, "train/mfu": 0.024512303251523985, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 92, "data": {"train/loss": 0.4692344069480896, "train/grad_norm": 1.607263445854187, "train/lr": 4.600000000000001e-06, "train/mfu": 0.024489369312603232, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 93, "data": {"train/loss": 0.4724048972129822, "train/grad_norm": 1.4867252111434937, "train/lr": 4.65e-06, "train/mfu": 0.024292877983095918, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 94, "data": {"train/loss": 0.45690399408340454, "train/grad_norm": 1.4581780433654785, "train/lr": 4.7e-06, "train/mfu": 0.024525742055149163, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 95, "data": {"train/loss": 0.4712291955947876, "train/grad_norm": 1.5585882663726807, "train/lr": 4.75e-06, "train/mfu": 0.024651005601395076, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 96, "data": {"train/loss": 0.4720529615879059, "train/grad_norm": 1.4406999349594116, "train/lr": 4.800000000000001e-06, "train/mfu": 0.024242058848626343, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 97, "data": {"train/loss": 0.4732741713523865, "train/grad_norm": 1.5345925092697144, "train/lr": 4.85e-06, "train/mfu": 0.024152636496244738, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 98, "data": {"train/loss": 0.4238469898700714, "train/grad_norm": 1.4769235849380493, "train/lr": 4.9000000000000005e-06, "train/mfu": 0.024288578481978077, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 99, "data": {"train/loss": 0.5002506375312805, "train/grad_norm": 1.5023456811904907, "train/lr": 4.95e-06, "train/mfu": 0.02445026889933752, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 100, "data": {"train/loss": 0.4506361782550812, "train/grad_norm": 1.4692397117614746, "train/lr": 5e-06, "train/mfu": 0.024209921863940245, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 101, "data": {"train/loss": 0.42525196075439453, "train/grad_norm": 1.4389604330062866, "train/lr": 5.050000000000001e-06, "train/mfu": 0.02436840486849471, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 102, "data": {"train/loss": 0.5042070150375366, "train/grad_norm": 1.701578974723816, "train/lr": 5.1e-06, "train/mfu": 0.02458726372237921, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 103, "data": {"train/loss": 0.4492676556110382, "train/grad_norm": 1.5178085565567017, "train/lr": 5.150000000000001e-06, "train/mfu": 0.024283650263126667, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 104, "data": {"train/loss": 0.4528452455997467, "train/grad_norm": 1.437851071357727, "train/lr": 5.2e-06, "train/mfu": 0.024622989505411332, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 105, "data": {"train/loss": 0.4304048717021942, "train/grad_norm": 1.3820306062698364, "train/lr": 5.2500000000000006e-06, "train/mfu": 0.024364828210044546, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 106, "data": {"train/loss": 0.44001591205596924, "train/grad_norm": 1.4566198587417603, "train/lr": 5.300000000000001e-06, "train/mfu": 0.024320852199194096, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 107, "data": {"train/loss": 0.448560893535614, "train/grad_norm": 1.4865374565124512, "train/lr": 5.3500000000000004e-06, "train/mfu": 0.024034003650123193, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 108, "data": {"train/loss": 0.4638853073120117, "train/grad_norm": 1.4780592918395996, "train/lr": 5.400000000000001e-06, "train/mfu": 0.02423317882253446, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 109, "data": {"train/loss": 0.43059468269348145, "train/grad_norm": 1.4211686849594116, "train/lr": 5.450000000000001e-06, "train/mfu": 0.0242807002159829, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 110, "data": {"train/loss": 0.4567106068134308, "train/grad_norm": 1.4903554916381836, "train/lr": 5.500000000000001e-06, "train/mfu": 0.024056846121131105, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 111, "data": {"train/loss": 0.43789902329444885, "train/grad_norm": 1.4818557500839233, "train/lr": 5.550000000000001e-06, "train/mfu": 0.02416188372019711, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 112, "data": {"train/loss": 0.44244876503944397, "train/grad_norm": 1.4771373271942139, "train/lr": 5.600000000000001e-06, "train/mfu": 0.024375760231519862, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 113, "data": {"train/loss": 0.4164450168609619, "train/grad_norm": 1.518905520439148, "train/lr": 5.65e-06, "train/mfu": 0.024099683713791814, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 114, "data": {"train/loss": 0.47595471143722534, "train/grad_norm": 1.4814915657043457, "train/lr": 5.7e-06, "train/mfu": 0.02411042495241539, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 115, "data": {"train/loss": 0.47495773434638977, "train/grad_norm": 1.524381160736084, "train/lr": 5.75e-06, "train/mfu": 0.024586092726244818, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 116, "data": {"train/loss": 0.484752893447876, "train/grad_norm": 1.476032018661499, "train/lr": 5.8e-06, "train/mfu": 0.024076579040612126, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 116, "data": {"val/loss": 0.46795544028282166}}
