{"step": 1, "data": {"train/loss": 1.3719072341918945, "train/grad_norm": 22.650300979614258, "train/lr": 5.0000000000000004e-08, "train/mfu": 0.01635841187945167, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 2, "data": {"train/loss": 1.4301011562347412, "train/grad_norm": 22.23706817626953, "train/lr": 1.0000000000000001e-07, "train/mfu": 0.02377621894929011, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 3, "data": {"train/loss": 1.3444151878356934, "train/grad_norm": 21.438636779785156, "train/lr": 1.5000000000000002e-07, "train/mfu": 0.02999639765870143, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 4, "data": {"train/loss": 1.3845412731170654, "train/grad_norm": 21.56836700439453, "train/lr": 2.0000000000000002e-07, "train/mfu": 0.02947843946023625, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 5, "data": {"train/loss": 1.4231441020965576, "train/grad_norm": 22.889305114746094, "train/lr": 2.5000000000000004e-07, "train/mfu": 0.02982250006166225, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 6, "data": {"train/loss": 1.3700220584869385, "train/grad_norm": 20.785367965698242, "train/lr": 3.0000000000000004e-07, "train/mfu": 0.030103999389486324, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 7, "data": {"train/loss": 1.378269910812378, "train/grad_norm": 22.387632369995117, "train/lr": 3.5000000000000004e-07, "train/mfu": 0.03009246272655801, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 8, "data": {"train/loss": 1.3691413402557373, "train/grad_norm": 22.666154861450195, "train/lr": 4.0000000000000003e-07, "train/mfu": 0.030291279505205868, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 9, "data": {"train/loss": 1.3349491357803345, "train/grad_norm": 22.206676483154297, "train/lr": 4.5000000000000003e-07, "train/mfu": 0.029711252762700237, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 10, "data": {"train/loss": 1.4388307332992554, "train/grad_norm": 23.210233688354492, "train/lr": 5.000000000000001e-07, "train/mfu": 0.02922721857728115, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 11, "data": {"train/loss": 1.3930509090423584, "train/grad_norm": 20.976547241210938, "train/lr": 5.5e-07, "train/mfu": 0.029749722050038, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 12, "data": {"train/loss": 1.3786098957061768, "train/grad_norm": 21.327621459960938, "train/lr": 6.000000000000001e-07, "train/mfu": 0.030011007395561288, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 13, "data": {"train/loss": 1.3608934879302979, "train/grad_norm": 20.82068634033203, "train/lr": 6.5e-07, "train/mfu": 0.029846869032899095, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 14, "data": {"train/loss": 1.3524725437164307, "train/grad_norm": 19.421077728271484, "train/lr": 7.000000000000001e-07, "train/mfu": 0.030030738175787917, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 15, "data": {"train/loss": 1.3255574703216553, "train/grad_norm": 19.469078063964844, "train/lr": 7.5e-07, "train/mfu": 0.030053696358769325, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 16, "data": {"train/loss": 1.2698285579681396, "train/grad_norm": 17.3016414642334, "train/lr": 8.000000000000001e-07, "train/mfu": 0.030032588251163034, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 17, "data": {"train/loss": 1.3418930768966675, "train/grad_norm": 18.320941925048828, "train/lr": 8.500000000000001e-07, "train/mfu": 0.030482011651209798, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 18, "data": {"train/loss": 1.2838587760925293, "train/grad_norm": 17.270587921142578, "train/lr": 9.000000000000001e-07, "train/mfu": 0.029944889238101405, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 19, "data": {"train/loss": 1.2852113246917725, "train/grad_norm": 19.020034790039062, "train/lr": 9.500000000000001e-07, "train/mfu": 0.030104616059472476, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 20, "data": {"train/loss": 1.177564263343811, "train/grad_norm": 16.300378799438477, "train/lr": 1.0000000000000002e-06, "train/mfu": 0.030515369124302513, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 21, "data": {"train/loss": 1.184518575668335, "train/grad_norm": 16.42354965209961, "train/lr": 1.0500000000000001e-06, "train/mfu": 0.030442451925917255, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 22, "data": {"train/loss": 1.1501704454421997, "train/grad_norm": 15.844250679016113, "train/lr": 1.1e-06, "train/mfu": 0.02978326466662152, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 23, "data": {"train/loss": 1.1217608451843262, "train/grad_norm": 16.290048599243164, "train/lr": 1.1500000000000002e-06, "train/mfu": 0.02968704401093538, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 24, "data": {"train/loss": 1.1224441528320312, "train/grad_norm": 16.566509246826172, "train/lr": 1.2000000000000002e-06, "train/mfu": 0.0299970951081283, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 25, "data": {"train/loss": 1.1622951030731201, "train/grad_norm": 19.119047164916992, "train/lr": 1.25e-06, "train/mfu": 0.02986184754524653, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 26, "data": {"train/loss": 1.055854320526123, "train/grad_norm": 17.768571853637695, "train/lr": 1.3e-06, "train/mfu": 0.03014369038987949, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 27, "data": {"train/loss": 0.9025158882141113, "train/grad_norm": 10.738990783691406, "train/lr": 1.3500000000000002e-06, "train/mfu": 0.030270281741910352, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 28, "data": {"train/loss": 0.8743748664855957, "train/grad_norm": 10.12603759765625, "train/lr": 1.4000000000000001e-06, "train/mfu": 0.030134003099749545, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 29, "data": {"train/loss": 0.8666521310806274, "train/grad_norm": 9.830747604370117, "train/lr": 1.45e-06, "train/mfu": 0.029353920770498823, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 30, "data": {"train/loss": 0.844429612159729, "train/grad_norm": 10.112947463989258, "train/lr": 1.5e-06, "train/mfu": 0.030221225743710115, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 31, "data": {"train/loss": 0.7949717044830322, "train/grad_norm": 9.281524658203125, "train/lr": 1.5500000000000002e-06, "train/mfu": 0.030621262916799338, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 32, "data": {"train/loss": 0.8295428156852722, "train/grad_norm": 8.894576072692871, "train/lr": 1.6000000000000001e-06, "train/mfu": 0.03009363463239812, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 33, "data": {"train/loss": 0.8434637784957886, "train/grad_norm": 8.717329978942871, "train/lr": 1.6500000000000003e-06, "train/mfu": 0.03010512755295867, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 34, "data": {"train/loss": 0.7490687370300293, "train/grad_norm": 8.430631637573242, "train/lr": 1.7000000000000002e-06, "train/mfu": 0.030413072200134384, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 35, "data": {"train/loss": 0.723874568939209, "train/grad_norm": 7.458385944366455, "train/lr": 1.75e-06, "train/mfu": 0.03025286098477214, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 36, "data": {"train/loss": 0.7254645824432373, "train/grad_norm": 6.279821872711182, "train/lr": 1.8000000000000001e-06, "train/mfu": 0.03111313334114505, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 37, "data": {"train/loss": 0.660737156867981, "train/grad_norm": 5.700077056884766, "train/lr": 1.85e-06, "train/mfu": 0.030564985782021818, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
{"step": 38, "data": {"train/loss": 0.6685318350791931, "train/grad_norm": 5.825051307678223, "train/lr": 1.9000000000000002e-06, "train/mfu": 0.030713528379665875, "train/global_tokens": 0.0, "train/total_tokens(B)": 0.0}}
